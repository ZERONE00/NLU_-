{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from utils import *\n",
    "from dataset import *\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "from model import *\n",
    "from config import *\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "import numpy as np\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 44974/44974 [00:17<00:00, 2518.53it/s]\n100%|██████████| 5621/5621 [00:02<00:00, 2427.35it/s]\n100%|██████████| 5624/5624 [00:02<00:00, 2530.56it/s]\n100%|██████████| 44974/44974 [00:18<00:00, 2469.69it/s]\n100%|██████████| 5621/5621 [00:02<00:00, 2357.62it/s]\n100%|██████████| 5621/5621 [00:02<00:00, 2188.04it/s]\n"
    }
   ],
   "source": [
    "tokens = get_tokens(dir='../data/csv/without_name/')\n",
    "\n",
    "token2id, id2token = get_token_id(tokens)\n",
    "\n",
    "dfs = read_data(dir='../data/csv/without_name/')\n",
    "x_train, y_train = get_input(dfs[0], token2id)\n",
    "x_test, y_test = get_input(dfs[1], token2id)\n",
    "x_valid, y_valid = get_input(dfs[1], token2id)\n",
    "x_train, x_test, x_valid = padding(x_train), padding(x_test), padding(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "training_set = dataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(training_set, batch_size=config.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "valid_set = dataset(x_valid, y_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=config.batch_size, num_workers=4)\n",
    "\n",
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format('../data/sgns.wiki.bigram-char', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_weights = torch.zeros((len(token2id)+1, config.embed))\n",
    "for token in token2id:\n",
    "    index = token2id[token]\n",
    "    embedding_weights[index, :] = torch.from_numpy(wv[token]) if token in wv else torch.rand(config.embed)\n",
    "embedding_weights = embedding_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, data_loader):\n",
    "    model.eval()\n",
    "    Y_true, Y_pre, hits = np.array([]), np.array([]), 0\n",
    "    for x, y in data_loader:\n",
    "        #print(y.shape)\n",
    "        Y_true = np.concatenate((Y_true, y.detach().numpy()))\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        y_pre = torch.argmax(output, dim=1).detach()\n",
    "        Y_pre = np.concatenate((Y_pre, y_pre.cpu().detach().numpy()))\n",
    "        hits += torch.sum(y==y_pre)\n",
    "\n",
    "    #return Y_true, Y_pre\n",
    "    matrix = confusion_matrix(Y_true, Y_pre)\n",
    "    score  = precision_score(Y_true, Y_pre, labels=[0, 1, 2], average='micro')\n",
    "    return hits, score, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training\n",
    "config.num_epochs = 200\n",
    "config.learning_rate = 5e-4\n",
    "\n",
    "model = TextCNN(embedding_weights, config)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "model.train()\n",
    "writer = SummaryWriter(log_dir=config.log_path + '/' + time.strftime('%m-%d_%H.%M', time.localtime()))\n",
    "step, eval_fre, log_fre, total_loss, best_hits = 1, 1, 100, 0, 0\n",
    "\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(filename='../runs/my.log', level=logging.DEBUG, format=LOG_FORMAT)\n",
    "\n",
    "for epoch in range(1, config.num_epochs+1):\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        #print(total_loss)\n",
    "        if step % log_fre == 0:\n",
    "            logging.info('after {} steps, mean loss is {}'.format(step, round(total_loss/log_fre, 4)))\n",
    "            writer.add_scalar('Loss/train-loss', total_loss/log_fre, step)\n",
    "            total_loss = 0\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    if epoch % eval_fre == 0:\n",
    "        tmp_hits, score, _ = eval(model, valid_loader)\n",
    "        if tmp_hits > best_hits:\n",
    "            best_hits = tmp_hits\n",
    "            torch.save(model.state_dict(), '../runs/best_model'.format(tmp_hits))\n",
    "        #torch.save(model.state_dict(), '../runs/model_epoch={}'.format(epoch))\n",
    "        writer.add_scalar('Loss/valid-micro_precision', score, epoch)\n",
    "        writer.add_scalar('hits/hits', tmp_hits, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = dataset(x_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=config.batch_size, num_workers=4)\n",
    "\n",
    "best_model = TextCNN(embedding_weights, config)\n",
    "best_model.load_state_dict(torch.load('../runs/best_model'))\n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1768    6    4]\n [  12 1872    6]\n [  49   32 1872]]\n"
    }
   ],
   "source": [
    "best_model.eval()\n",
    "_, _, score = eval(best_model, test_loader)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit ('py36': conda)",
   "language": "python",
   "name": "python_defaultSpec_1596966428694"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}