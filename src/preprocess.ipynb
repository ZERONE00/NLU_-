{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596093343530",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取csv，如果不存在cut_words列则进行添加并写入原来的csv文件中\n",
    "def append_cut_words(path, keep_name=True, reset=False, saved=True):\n",
    "    df = pd.read_csv(path)\n",
    "    if 'cut_words' in list(df.columns) and not reset:\n",
    "        return df\n",
    "\n",
    "    if keep_name:\n",
    "        # 保留人名，直接分词后进行处理\n",
    "        doc_words = [list(jieba.cut(doc)) for doc in tqdm(df['txt'])]\n",
    "    else:\n",
    "        # 不保留人名，去除nr后进行处理\n",
    "        doc_words = [[word for word, tag in pseg.cut(doc) if tag != 'nr'] for doc in tqdm(df['txt'])]\n",
    "\n",
    "    cut_words_all = [\" \".join(cut_doc) for cut_doc in doc_words]\n",
    "    df['cut_words'] = cut_words_all\n",
    "    \n",
    "    if saved:\n",
    "        df.to_csv(path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "start cut doc in ../data/csv/train.csv...\n100%|██████████| 44974/44974 [01:54<00:00, 359.11it/s]\n  0%|          | 24/5621 [00:00<00:23, 233.70it/s]start cut doc in ../data/csv/test.csv...\n100%|██████████| 5621/5621 [00:14<00:00, 368.65it/s]\n  0%|          | 28/5624 [00:00<00:20, 274.56it/s]start cut doc in ../data/csv/valid.csv...\n100%|██████████| 5624/5624 [00:14<00:00, 395.24it/s]\n"
    }
   ],
   "source": [
    "for fname in ['train.csv', 'test.csv', 'valid.csv']:\n",
    "    path = os.path.join('../data/csv/', fname)\n",
    "    print('start cut doc in {}...'.format(path))\n",
    "    append_cut_words(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "start cut doc in ../data/csv/train.csv...\n100%|██████████| 44974/44974 [24:26<00:00, 30.68it/s]\n  0%|          | 0/5621 [00:00<?, ?it/s]start cut doc in ../data/csv/test.csv...\n100%|██████████| 5621/5621 [03:13<00:00, 29.11it/s]\n  0%|          | 0/5624 [00:00<?, ?it/s]start cut doc in ../data/csv/valid.csv...\n100%|██████████| 5624/5624 [03:00<00:00, 31.22it/s]\n"
    }
   ],
   "source": [
    "for fname in ['train.csv', 'test.csv', 'valid.csv']:\n",
    "    path = os.path.join('../data/csv/', fname)\n",
    "    print('start cut doc in {}...'.format(path))\n",
    "    df = append_cut_words(path, keep_name=False, reset=True, saved=False)\n",
    "    to_path = os.path.join('../data/csv/without_name/', fname)\n",
    "    df.to_csv(to_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}